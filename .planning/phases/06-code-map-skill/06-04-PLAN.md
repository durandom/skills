---
phase: 06-code-map-skill
plan: 04
type: execute
---

<objective>
Create map generation workflow and LSP-based validation.

Purpose: Enable agents to create maps for new codebases and verify map integrity using proper language server validation.
Output: workflows/create-map.md and Python-based validation with TDD.
</objective>

<execution_context>
@.claude/skills/create-plans/workflows/execute-phase.md
@.claude/skills/create-plans/templates/summary.md
</execution_context>

<context>
@.planning/phases/06-code-map-skill/BRIEF.md
@.planning/phases/06-code-map-skill/06-03-SUMMARY.md
@.claude/skills/code-map/SKILL.md
@.claude/skills/code-map/references/format-spec.md
@.claude/skills/code-map/workflows/explore.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test fixtures for validation</name>
  <files>.claude/skills/code-map/scripts/tests/fixtures/</files>
  <action>
Create test fixtures that represent valid and invalid maps:

```
scripts/tests/fixtures/
├── valid_map/
│   ├── MAP.md
│   ├── ARCHITECTURE.md
│   └── domains/
│       └── core.md
├── broken_links/
│   └── MAP.md           # Has [[L1:nonexistent]]
├── broken_symbols/
│   └── domains/
│       └── bad.md       # Has src/foo.py:missing_func
└── sample_code/
    └── src/
        └── example.py   # Real Python file with symbols
```

The sample_code/src/example.py should have:

- A class `ExampleClass`
- A function `example_function`
- A method `ExampleClass.example_method`

These fixtures enable TDD for all validation scenarios.
  </action>
  <verify>ls -R .claude/skills/code-map/scripts/tests/fixtures/ shows all fixtures</verify>
  <done>Test fixtures created for valid/invalid scenarios</done>
</task>

<task type="auto">
  <name>Task 2: Create LSP client module with tests</name>
  <files>.claude/skills/code-map/scripts/lsp_client.py, .claude/skills/code-map/scripts/tests/test_lsp_client.py</files>
  <action>
TDD approach - write tests first, then implementation.

**Test cases (test_lsp_client.py):**

```python
def test_symbol_exists_for_function():
    """Pyright finds top-level function."""

def test_symbol_exists_for_class():
    """Pyright finds class definition."""

def test_symbol_exists_for_method():
    """Pyright finds method within class."""

def test_symbol_not_found():
    """Returns False for nonexistent symbol."""

def test_handles_missing_file():
    """Graceful handling of missing files."""
```

**Implementation (lsp_client.py):**

- Use subprocess to call `pyright --outputjson`
- Parse JSON output for symbol definitions
- Function: `symbol_exists(file_path: str, symbol: str) -> bool`
- Function: `get_symbols(file_path: str) -> list[Symbol]`

Keep it simple - just wraps Pyright CLI, no full LSP protocol needed.
Pyright JSON mode gives us what we need without complexity.
  </action>
  <verify>pytest .claude/skills/code-map/scripts/tests/test_lsp_client.py -v passes</verify>
  <done>LSP client with passing tests</done>
</task>

<task type="auto">
  <name>Task 3: Create map validator module with tests</name>
  <files>.claude/skills/code-map/scripts/validate_map.py, .claude/skills/code-map/scripts/tests/test_validate_map.py</files>
  <action>
TDD approach - write tests first, then implementation.

**Test cases (test_validate_map.py):**

```python
def test_validates_structure():
    """Checks MAP.md, ARCHITECTURE.md, domains/ exist."""

def test_finds_broken_file_links():
    """[Text](nonexistent.md) detected as error."""

def test_validates_file_links():
    """[Text](existing.md) passes when file exists."""

def test_finds_broken_code_links():
    """[`symbol`](file.py#L99) - wrong line number detected."""

def test_validates_code_links():
    """[`symbol`](file.py#L42) passes via LSP."""

def test_checks_size_limits():
    """Files over limit flagged."""

def test_valid_map_passes():
    """Complete valid map returns no errors."""
```

**Implementation (validate_map.py):**

```python
@dataclass
class ValidationError:
    file: str
    line: int
    message: str
    error_type: str  # "broken_link", "broken_symbol", "size_limit"

def validate_map(map_dir: Path) -> list[ValidationError]:
    """Main entry point."""

def check_structure(map_dir: Path) -> list[ValidationError]:
    """Verify required files exist."""

def check_file_links(map_dir: Path) -> list[ValidationError]:
    """All [text](path.md) links resolve to existing files."""

def check_code_links(map_dir: Path) -> list[ValidationError]:
    """All [`symbol`](file#L42) links validated via LSP."""

def check_size_limits(map_dir: Path) -> list[ValidationError]:
    """No files exceed their level's limit."""
```

Uses lsp_client for code reference validation.
  </action>
  <verify>pytest .claude/skills/code-map/scripts/tests/test_validate_map.py -v passes</verify>
  <done>Map validator with passing tests</done>
</task>

<task type="auto">
  <name>Task 4: Create CLI entry point</name>
  <files>.claude/skills/code-map/scripts/__main__.py</files>
  <action>
Create CLI that can be run as:
```bash
python -m scripts.validate_map docs/map
```

Output format:

```
Validating docs/map...

Structure: ✓
File links: ✓ (12 checked)
Code links: ✓ (8 checked, LSP)
Size limits: ✓

All checks passed.
```

Or with errors:

```
Validating docs/map...

Structure: ✓
File links: ✗
  domains/auth.md:15 - [Config](config.md) → file not found
Code links: ✗
  domains/api.md:23 - [`missing_handler`](src/api.py#L99) → symbol not at line 99
Size limits: ✓

2 errors found.
```

Exit code 0 for success, 1 for errors.
  </action>
  <verify>python -m .claude.skills.code-map.scripts docs/map runs without crash</verify>
  <done>CLI entry point working</done>
</task>

<task type="auto">
  <name>Task 5: Create map generation workflow</name>
  <files>.claude/skills/code-map/workflows/create-map.md</files>
  <action>
Create workflow that guides agent through map creation:

1. **objective** section:
   - Generate hierarchical map for a codebase
   - Create grep-navigable documentation

2. **required_reading** section:
   - @.claude/skills/code-map/references/format-spec.md
   - @.claude/skills/code-map/templates/MAP.md
   - @.claude/skills/code-map/templates/L0-architecture.md
   - @.claude/skills/code-map/templates/L1-domain.md

3. **process** section with steps:

   Step 1: Analyze codebase
   - Count files by language
   - Identify entry points (main, cli, api)
   - Use LSP to discover key symbols

   Step 2: Identify domains
   - Group related functionality
   - Aim for 3-10 L1 domains
   - Ask user for confirmation

   Step 3: Create directory structure

   ```bash
   mkdir -p docs/map/domains
   ```

   Step 4: Create MAP.md
   - Copy template, fill placeholders
   - Use `## [L0:architecture]` anchor format

   Step 5: Create ARCHITECTURE.md
   - Copy L0 template
   - Use `## [L1:domain]` links

   Step 6: Create L1 domain docs
   - Use `file:symbol` notation
   - LSP validates symbols exist

   Step 7: Validate
   - Run: `python -m .claude.skills.code-map.scripts docs/map`
   - Fix any errors

4. **success_criteria** section:
   - Validation passes
   - All placeholders filled
   - Size limits respected
  </action>

  <verify>cat .claude/skills/code-map/workflows/create-map.md shows complete workflow</verify>
  <done>Create workflow documented</done>
</task>

<task type="auto">
  <name>Task 6: Validate fvtt2obsidian test map</name>
  <files>None (testing only)</files>
  <action>
Run validation on the test map from Plan 03:

```bash
python -m .claude.skills.code-map.scripts docs/map
```

Expected: All checks pass.

If errors:

1. Fix broken references in test map
2. Or fix validation logic if false positives
3. Document any edge cases discovered
  </action>

  <verify>Validation exits 0 on test map</verify>
  <done>Validation tested end-to-end</done>
</task>

<task type="auto">
  <name>Task 7: Update SKILL.md routing</name>
  <files>.claude/skills/code-map/SKILL.md</files>
  <action>
Update SKILL.md to reflect completed workflows:

1. Update workflows_index with actual status:
   - explore.md - exists (ready)
   - create-map.md - exists (ready)
2. Add validate routing:
   - validate → Run `python -m .claude.skills.code-map.scripts <map-dir>`
3. Update routing table with all three options
4. Ensure all POC options functional
  </action>

  <verify>grep "validate" .claude/skills/code-map/SKILL.md shows routing</verify>
  <done>SKILL.md complete for POC</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All test fixtures exist
- [ ] `pytest .claude/skills/code-map/scripts/tests/ -v` all pass
- [ ] CLI validates test map successfully
- [ ] Create workflow documented
- [ ] SKILL.md routes all POC options
</verification>

<success_criteria>

- All tasks completed
- TDD approach followed (tests first)
- LSP-based symbol validation working
- Full POC functional
- Ready for milestone v0.1
</success_criteria>

<output>
After completion, create `.planning/phases/06-code-map-skill/06-04-SUMMARY.md`
</output>
